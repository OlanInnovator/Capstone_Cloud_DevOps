# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/configuration-reference
# Python CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1
# Orbs are reusable packages of CircleCI configuration that you may share across projects, enabling you to create encapsulated, parameterized commands, jobs, and executors that can be used across multiple projects.
# See: https://circleci.com/docs/orb-intro/
orbs:
  # The python orb contains a set of prepackaged CircleCI configuration you can use repeatedly in your configuration files
  # Orb commands and jobs help you with common scripting around a language/tool
  # so you dont have to copy and paste it everywhere.
  # See the orb documentation here: https://circleci.com/developer/orbs/orb/circleci/python
  python: circleci/python@1.5.0
  aws-cli: circleci/aws-cli@2.0.3

commands:
  # Exercise: Reusable Job Code
  print_pipeline_id:
    parameters:
      id: 
        type: string
    steps:
      - run: echo << parameters.id >>

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/configuration-reference/#jobs
jobs:
  create-cluster: 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Cloudformation Cluster Stack
          command: |
            aws cloudformation deploy --template-file ./templateCluster.yml --stack-name "capstoneclusterProd-${oldWorkFlowID}" --parameter-overrides = --capabilities CAPABILITY_NAMED_IAM CAPABILITY_AUTO_EXPAND      
      - run:
          name: Create Cloudformation Cluster Stack
          command: |
            aws cloudformation deploy --template-file ./templateCluster.yml --stack-name "capstoneclusterProd-${oldWorkFlowID}" --parameter-overrides = --capabilities CAPABILITY_NAMED_IAM CAPABILITY_AUTO_EXPAND
      
      # - run: return 1
     # - destroy_environment

  # Exercise: Config and Deployment
  configure_infrastructure: 
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["SHA256:ATm5cgo5+68fvMKhXz/AItoTGu2FQ+TImSi/99cK+c8"] # You can get this ID in the section where you registered the SSH Key
      - run:
          name: Install dependencies
          command: |
            # install the dependencies needed for your playbook
            apk add --update ansible 
      - run:
          name: Configure server
          command: |
            ansible-playbook -i inventory.txt main4.yml
              # Exercise - Rollback          
  cleanup:
     docker:
       - image: amazon/aws-cli
     steps:
      - checkout
      - run:
           name: Get old stack workflow id & Remove old stack and files
           command: |
             export OldWorkflowID=$(aws cloudformation \
                   list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
                   --no-paginate --output text)
             echo OldWorkflowID: "${OldWorkflowID}"
             echo CIRCLE_WORKFLOW_ID "${CIRCLE_WORKFLOW_ID:0:7}"
              # Fetch the stack names         
             export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
                   --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
               echo Stack names: "${STACKS[@]}"
              for OldWorkflowID in "${STACKS[@]}"; do
              if [[ "${CIRCLE_WORKFLOW_ID:0:7}" =~ $OldWorkflowID ]]
              then
                echo ------ Cleaning up old jobs ------
                aws s3 rm "s3://${oldWorkFlowID}" --recursive
                aws cloudformation delete-stack --stack-name "capstoneclusterProd-${oldWorkFlowID}"
                # aws cloudformation delete-stack --stack-name "capstoneclusterProd-${OldWorkFlowID}"
                # aws cloudformation delete-stack --stack-name "capstoneclusterProd-${OldWorkFlowID}"
              else
                 echo ------ Nothing to cleanup - "Current: $OldWorkflowID" ------
              fi
              done          

  build:
    docker:
        # Use the same Docker base as the project
      - image: python:3.7
    working_directory: ~/Capstone_Cloud_DevOps
    steps:
      - checkout
# Download and cache dependencies
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "~/Capstone_Cloud_DevOps/requirements.txt" }}
        # fallback to using the latest cache if no exact match is found
          - v1-dependencies-
      - run:
          name: install dependencies
          command: |
            # cd ~/Capstone_Cloud_DevOps
            python3.7 -m venv venv
            . venv/bin/activate
            make install
            # Install hadolint
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 &&\
            chmod +x /bin/hadolint
      - save_cache:
          paths:
          - ./venv
          key: v1-dependencies-{{ checksum "~/Capstone_Cloud_DevOps/requirements.txt" }}
      # run lint!
      - run:
          name: run lint
          command: |
            # cd ~/Capstone_Cloud_DevOps
            . venv/bin/activate
            make lint 
      # Build Docker!
      - run:
          name: run docker
          command: |
            # cd ~/Capstone_Cloud_DevOps
            . venv/bin/activate
            ./run_docker.sh 
    
  test-build: # This is the name of the job, feel free to change it to better match what you're trying to do!
    # These next lines defines a Docker executors: https://circleci.com/docs/executor-types/
    # You can specify an image from Dockerhub or use one of the convenience images from CircleCI's Developer Hub
    # A list of available CircleCI Docker convenience images are available here: https://circleci.com/developer/images/image/cimg/python
    # The executor is the environment in which the steps below will be executed - below will use a python 3.10.2 container
    # Change the version below to your required version of python
    docker:
      - image: cimg/python:3.7
    # Checkout the code as the first step. This is a dedicated CircleCI step.
    # The python orb's install-packages step will install the dependencies from a Pipfile via Pipenv by default.
    # Here we're making sure we use just use the system-wide pip. By default it uses the project root's requirements.txt.
    # Then run your tests!
    # CircleCI will report the results back to your VCS provider.
    steps:
      - checkout
      - python/install-packages:
          pkg-manager: pip
          # app-dir: ~/project/package-directory/  # If your requirements.txt isn't in the root directory.
          # pip-dependency-file: test-requirements.txt  # if you have a different name for your requirements file, maybe one that combines your runtime and test requirements.
      - run:
          name: Run tests
          # This assumes pytest is installed via the install-package step above
          command: |
              #cd ~/Capstone_Cloud_DevOps
              pip install -U pytest
              python3.7 -m pytest -vv test/*.py

# Invoke jobs via workflows
# See: https://circleci.com/docs/configuration-reference/#workflows
workflows:
  capston: # This is the name of the workflow, feel free to change it to better match your workflow.
    # Inside the workflow, you define the jobs you want to run.
    jobs:
      - test-build
      - build
      #- create_infrastructure
